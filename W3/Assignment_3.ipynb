{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/VVDRNHZQp4KvveKMweVP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrAlexSanz/NLP-SPEC-C4/blob/main/W3/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwD_WV2S4MZE"
      },
      "source": [
        "# Assignment 3: Question Answering\r\n",
        "Welcome to this week's assignment of course 4. In this you will explore question answering. You will implement the \"Text to Text Transfer from Transformers\" (better known as T5). Since you implemented transformers from scratch last week you will now be able to use them.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEZrN51o4Ryz"
      },
      "source": [
        "## Overview\r\n",
        "This assignment will be different from the two previous ones. Due to memory and time constraints of this environment you will not be able to train a model and use it for inference. Instead you will create the necessary building blocks for the transformer encoder model and will use a pretrained version of the same model in two ungraded labs after this assignment.\r\n",
        "\r\n",
        "After completing these 3 (1 graded and 2 ungraded) labs you will:\r\n",
        "\r\n",
        "Implement the code neccesary for Bidirectional Encoder Representation from Transformer (BERT).\r\n",
        "Understand how the C4 dataset is structured.\r\n",
        "Use a pretrained model for inference.\r\n",
        "Understand how the \"Text to Text Transfer from Transformers\" or T5 model works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYKBE6LU5xpm"
      },
      "source": [
        "Overview\r\n",
        "This assignment will be different from the two previous ones. Due to memory and time constraints of this environment you will not be able to train a model and use it for inference. Instead you will create the necessary building blocks for the transformer encoder model and will use a pretrained version of the same model in two ungraded labs after this assignment.\r\n",
        "\r\n",
        "After completing these 3 (1 graded and 2 ungraded) labs you will:\r\n",
        "\r\n",
        "* Implement the code neccesary for Bidirectional Encoder Representation from Transformer (BERT).\r\n",
        "* Understand how the C4 dataset is structured.\r\n",
        "* Use a pretrained model for inference.\r\n",
        "* Understand how the \"Text to Text Transfer from Transformers\" or T5 model works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wZdg13V52Lg"
      },
      "source": [
        "import string\r\n",
        "import textwrap\r\n",
        "import itertools\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import trax \r\n",
        "from trax import layers as tl\r\n",
        "from trax.supervised import decoding\r\n",
        "\r\n",
        "# Will come handy later.\r\n",
        "wrapper = textwrap.TextWrapper(width=70)\r\n",
        "\r\n",
        "# Set random seed\r\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia8Xl9ef6UnY",
        "outputId": "52f4beb9-a569-47bd-e3ec-64f89ff37665"
      },
      "source": [
        "!git clone https://github.com/DrAlexSanz/NLP-SPEC-C4.git\r\n",
        "\r\n",
        "!mv \"NLP-SPEC-C4/W3/data.txt\" \"./\"\r\n",
        "!mv \"NLP-SPEC-C4/W3/example.txt\" \"./\"\r\n",
        "!rm -rf \"NLP-SPEC-C4\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLP-SPEC-C4'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 102 (delta 26), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (102/102), 1.81 MiB | 6.05 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ianNZQeA6-p3"
      },
      "source": [
        "# Part 1: C4 Dataset\r\n",
        "The C4 is a huge data set. For the purpose of this assignment you will use a few examples out of it which are present in data.txt. C4 is based on the common crawl project. Feel free to read more on their website.\r\n",
        "\r\n",
        "Run the cell below to see how the examples look like."
      ]
    }
  ]
}